# Pong-Agent

The Pong-Agent implements Q learning with Deep Q networks and experience replay.

For this agent, all training was done in a Jupyter notebook called "main.ipynb". 
- Following through this jupyter notebook, you will see that there is a set of cells for 
  - initializing and training the network, followed by 
  - cells for saving the network, followed by 
  - cells for watching the bot play itself, or playing against it yourself. 
- There are also files to observe the training process, and updates to weights and biases.
  - Training loss example
    ![Alt text](docs/TrainingLoss.jpg?raw=true "Optional")
  - Layer input and output magnitudes example
    ![Alt text](docs/NetworkInputOutput.jpg?raw=true "Optional")